"""
Idea Refiner Node
ì‚¬ìš©ìì™€ ëŒ€í™”í˜• í‹°í‚¤íƒ€ì¹´ë¥¼ í†µí•´ ì´ˆê¸° ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ëŠ” ë…¸ë“œ
GPT + Claude í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ:
- GPT: ì§ˆë¬¸ ìƒì„±, ì¶©ë¶„ì„± íŒë‹¨ (ë¹ ë¥´ê³  ì €ë ´)
- Claude: ì•„ì´ë””ì–´ í•©ì„±, ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ (ì°½ì˜ì ì´ê³  ê³ í’ˆì§ˆ)
"""

from typing import Dict, Any, List, Optional
from utils.llm_client import LLMClient, HybridLLMClient
from utils.logger import get_logger

logger = get_logger("IdeaRefinerNode")


class IdeaRefinerNode:
    """ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ í†µí•´ ì•„ì´ë””ì–´ë¥¼ ì •êµí™”í•˜ëŠ” ë…¸ë“œ (GPT+Claude í•˜ì´ë¸Œë¦¬ë“œ)"""
    
    def __init__(self):
        self.gpt_client = LLMClient()  # ì§ˆë¬¸ ìƒì„±ìš© (ë¹ ë¦„)
        self.hybrid_client = HybridLLMClient()  # ì•„ì´ë””ì–´ í•©ì„±ìš© (ê³ í’ˆì§ˆ)
        self.conversation_history = []
        self.max_questions = 5  # ìµœëŒ€ ì§ˆë¬¸ íšŸìˆ˜
    
    def refine_interactive(self, initial_idea: str, auto_mode: bool = False) -> Dict[str, Any]:
        """
        ëŒ€í™”í˜• ì•„ì´ë””ì–´ ì •êµí™”
        
        Args:
            initial_idea: ì‚¬ìš©ìì˜ ì´ˆê¸° ì•„ì´ë””ì–´
            auto_mode: Trueë©´ ìë™ìœ¼ë¡œ ë‹µë³€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©), Falseë©´ ì‹¤ì œ ì…ë ¥ ë°›ìŒ
            
        Returns:
            {
                "initial_idea": str,
                "refined_idea": str,
                "conversation_history": List[Dict],
                "extracted_details": Dict
            }
        """
        logger.info(f"ğŸ’¡ ì´ˆê¸° ì•„ì´ë””ì–´: {initial_idea}")
        print("\n" + "="*80)
        print("ğŸ¯ ì•„ì´ë””ì–´ êµ¬ì²´í™” ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("="*80)
        print(f"\nğŸ’­ ì…ë ¥í•˜ì‹  ì•„ì´ë””ì–´: '{initial_idea}'\n")
        
        self.conversation_history = []
        current_context = initial_idea
        
        # 1ë‹¨ê³„: ì´ˆê¸° ë¶„ì„ ë° ì§ˆë¬¸ ìƒì„±
        for question_round in range(1, self.max_questions + 1):
            print(f"\n--- ì§ˆë¬¸ {question_round}/{self.max_questions} ---")
            
            # AIê°€ ì§ˆë¬¸ ìƒì„±
            question = self._generate_question(current_context, question_round)
            print(f"\nğŸ¤– AI: {question}")
            
            # ì‚¬ìš©ì ì‘ë‹µ ë°›ê¸°
            if auto_mode:
                answer = self._generate_auto_answer(question, current_context)
                print(f"ğŸ‘¤ (ìë™ ë‹µë³€): {answer}")
            else:
                answer = input("\nğŸ‘¤ ë‹µë³€: ").strip()
                
                # ì‚¬ìš©ìê°€ ì¶©ë¶„í•˜ë‹¤ê³  ìƒê°í•˜ë©´ ì¤‘ë‹¨ ê°€ëŠ¥
                if answer.lower() in ['ì¶©ë¶„', 'ì¶©ë¶„í•´', 'ê·¸ë§Œ', 'ì™„ë£Œ', 'done', 'skip']:
                    print("\nâœ… ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
                    break
                    
                if not answer:
                    print("âš ï¸  ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì¶©ë¶„í•˜ë‹¤ë©´ 'ì¶©ë¶„'ì´ë¼ê³  ì…ë ¥í•˜ì„¸ìš”)")
                    continue
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.conversation_history.append({
                "round": question_round,
                "question": question,
                "answer": answer
            })
            
            # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            current_context = self._update_context(current_context, question, answer)
            
            # ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ëŠ”ì§€ í™•ì¸
            if question_round >= 3:  # ìµœì†Œ 3ë²ˆì˜ ì§ˆë¬¸ í›„
                if self._is_sufficient_info(current_context):
                    print(f"\nâœ… ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {question_round}ë²ˆì˜ ì§ˆë¬¸)")
                    break
        
        # 2ë‹¨ê³„: ì •êµí™”ëœ ì•„ì´ë””ì–´ ìƒì„± (Claude ì‚¬ìš© - ì°½ì˜ì )
        logger.info("ğŸ¨ Claudeë¡œ ì•„ì´ë””ì–´ í•©ì„± ì¤‘...")
        refined_idea = self._synthesize_refined_idea(initial_idea, self.conversation_history)
        
        # 3ë‹¨ê³„: ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ (Claude ì‚¬ìš© - ë¶„ì„ì )
        logger.info("ğŸ“Š Claudeë¡œ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        extracted_details = self._extract_details(refined_idea, self.conversation_history)
        
        print("\n" + "="*80)
        print("âœ¨ ì•„ì´ë””ì–´ êµ¬ì²´í™” ì™„ë£Œ!")
        print("="*80)
        print(f"\nğŸ“Œ ì •êµí™”ëœ ì•„ì´ë””ì–´:\n{refined_idea}\n")
        
        result = {
            "initial_idea": initial_idea,
            "refined_idea": refined_idea,
            "conversation_history": self.conversation_history,
            "extracted_details": extracted_details
        }
        
        return result
    
    def _generate_question(self, context: str, round_num: int) -> str:
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± (GPT ì‚¬ìš© - ë¹ ë¦„)"""
        
        # ì§ˆë¬¸ ì˜ì—­ ì •ì˜
        question_areas = {
            1: "íƒ€ê²Ÿ ë…ìì™€ ëª©ì ",
            2: "ìˆ˜ìµì„± ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ìµœì  í”Œë«í¼ (ë„¤ì´ë²„/í‹°ìŠ¤í† ë¦¬/ë¸ŒëŸ°ì¹˜/ìœ íŠœë¸Œ ë“±)",
            3: "30-31ì¼ ë¡œí…Œì´ì…˜ ê°€ëŠ¥í•œ ì—ë²„ê·¸ë¦° ì†Œì£¼ì œ ë° ê¸€ê° ë°©í–¥ì„±",
            4: "ì°¨ë³„í™” í¬ì¸íŠ¸ì™€ ê²½ìŸ ìš°ìœ„",
            5: "ì¥ê¸° ì§€ì† ê°€ëŠ¥ì„± (ì—°ë‹¨ìœ„ ë°˜ë³µ í™œìš©)"
        }
        
        area = question_areas.get(round_num, "ì¶”ê°€ ì„¸ë¶€ì‚¬í•­")
        
        prompt = f"""ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œì‹œí•œ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:
{context}

í˜„ì¬ ë¼ìš´ë“œ: {round_num}
ì§ˆë¬¸ ì˜ì—­: {area}

ì´ì „ ëŒ€í™” ê¸°ë¡:
{self._format_conversation_history()}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ì´ë””ì–´ë¥¼ ë” êµ¬ì²´í™”í•  ìˆ˜ ìˆëŠ” **1ê°œì˜ í•µì‹¬ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì„¸ìš”.
ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•˜ë©°, ì‚¬ìš©ìê°€ ì‰½ê²Œ ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´):"""

        # GPT ì‚¬ìš© (ë¹ ë¥¸ ì§ˆë¬¸ ìƒì„±)
        response = self.gpt_client.chat(prompt=prompt, max_tokens=200)
        
        return response.strip()
    
    def _generate_auto_answer(self, question: str, context: str) -> str:
        """ìë™ ëª¨ë“œì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìë™ ìƒì„± (GPT ì‚¬ìš© - í…ŒìŠ¤íŠ¸ìš©)"""
        
        prompt = f"""í˜„ì¬ ì•„ì´ë””ì–´ ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
ë‹µë³€ì€ 1-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ë‹µë³€ë§Œ ì¶œë ¥í•˜ì„¸ìš”:"""

        # GPT ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš© ìë™ ë‹µë³€)
        response = self.gpt_client.chat(prompt=prompt, max_tokens=300)
        
        return response.strip()
    
    def _update_context(self, current_context: str, question: str, answer: str) -> str:
        """ëŒ€í™” ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        return f"""{current_context}

Q: {question}
A: {answer}"""
    
    def _format_conversation_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ì„ í¬ë§·íŒ…"""
        if not self.conversation_history:
            return "ì—†ìŒ"
        
        formatted = []
        for conv in self.conversation_history:
            formatted.append(f"Q{conv['round']}: {conv['question']}")
            formatted.append(f"A{conv['round']}: {conv['answer']}")
        
        return "\n".join(formatted)
    
    def _is_sufficient_info(self, context: str) -> bool:
        """ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ëŠ”ì§€ íŒë‹¨ (GPT ì‚¬ìš© - ë¹ ë¥¸ íŒë‹¨)"""
        
        # ìµœì†Œ 3ë²ˆì˜ ëŒ€í™”ê°€ ìˆì–´ì•¼ í•¨
        if len(self.conversation_history) < 3:
            return False
        
        # AIì—ê²Œ ì¶©ë¶„ì„± íŒë‹¨ ìš”ì²­
        prompt = f"""ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬, ë¸”ë¡œê·¸ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ê¸°ì— ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì˜€ëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
{context}

íŒë‹¨ ê¸°ì¤€:
1. íƒ€ê²Ÿ ë…ìê°€ ëª…í™•í•œê°€?
2. í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œê°€ êµ¬ì²´ì ì¸ê°€?
3. ì°¨ë³„í™” í¬ì¸íŠ¸ê°€ ìˆëŠ”ê°€?
4. ì½˜í…ì¸  ë°©í–¥ì„±ì´ ëª…í™•í•œê°€?

ì¶©ë¶„í•˜ë©´ "YES", ë” í•„ìš”í•˜ë©´ "NO"ë§Œ ë‹µí•˜ì„¸ìš”:"""

        # GPT ì‚¬ìš© (ë¹ ë¥¸ ì¶©ë¶„ì„± íŒë‹¨)
        response = self.gpt_client.chat(prompt=prompt, max_tokens=10)
        
        return "YES" in response.upper()
    
    def _synthesize_refined_idea(self, initial_idea: str, conversation: List[Dict]) -> str:
        """ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì •êµí™”ëœ ì•„ì´ë””ì–´ ìƒì„± (Claude ì‚¬ìš© - ì°½ì˜ì  í•©ì„±)"""
        
        conversation_text = "\n".join([
            f"Q: {c['question']}\nA: {c['answer']}" 
            for c in conversation
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì´ˆê¸° ì•„ì´ë””ì–´ì™€ ëŒ€í™” ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì •êµí™”ëœ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ì´ˆê¸° ì•„ì´ë””ì–´: {initial_idea}

ëŒ€í™” ë‚´ìš©:
{conversation_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •êµí™”ëœ ì•„ì´ë””ì–´ë¥¼ ì‘ì„±í•˜ì„¸ìš”:

[ë¸”ë¡œê·¸ ì£¼ì œ]
- í•µì‹¬ ì£¼ì œ: (í•œ ë¬¸ì¥)

[íƒ€ê²Ÿ ë…ì]
- (êµ¬ì²´ì ìœ¼ë¡œ)

[ì¶”ì²œ í”Œë«í¼]
- ë©”ì¸ í”Œë«í¼: (ë„¤ì´ë²„/í‹°ìŠ¤í† ë¦¬/ë¸ŒëŸ°ì¹˜/ì¸ìŠ¤íƒ€/ìœ íŠœë¸Œ ë“± ì¤‘ ìˆ˜ìµì„± ìµœì )
- ì´ìœ : (ì™œ ì´ í”Œë«í¼ì´ ìµœì ì¸ì§€)
- ë³´ì¡° í”Œë«í¼: (ì¶”ê°€ í™œìš© ê°€ëŠ¥í•œ í”Œë«í¼)

[30ì¼ ì—ë²„ê·¸ë¦° ì½˜í…ì¸  ì „ëµ]
- ë¡œí…Œì´ì…˜ ê°€ëŠ¥ ì†Œì£¼ì œ: (ê³„ì ˆ/íŠ¸ë Œë“œ ë¬´ê´€í•˜ê²Œ ì—°ì¤‘ í™œìš© ê°€ëŠ¥í•œ ì£¼ì œ 3-5ê°œ)
- ê¸€ê° ì¬í™œìš© ë°©ë²•: (ì–´ë–»ê²Œ ë§¤ë…„ ë°˜ë³µ í™œìš©í• ì§€)

[ì°¨ë³„í™” í¬ì¸íŠ¸]
- (2-3ê°œ í•­ëª©)

[ìˆ˜ìµí™” ì „ëµ]
- (ê´‘ê³ /ì œíœ´/ìƒí’ˆ ë“±)

[ê¸°ëŒ€ íš¨ê³¼]
- (ê°„ë‹¨íˆ)

ìœ„ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ì‘ì„±í•˜ì„¸ìš”:"""

        # Claude ì‚¬ìš© (ì°½ì˜ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì•„ì´ë””ì–´ í•©ì„±)
        response = self.hybrid_client.chat(
            prompt=prompt, 
            max_tokens=1000,
            task_type="creative"  # Claude ì‚¬ìš©
        )
        
        return response.strip()
    
    def _extract_details(self, refined_idea: str, conversation: List[Dict]) -> Dict[str, Any]:
        """ì •êµí™”ëœ ì•„ì´ë””ì–´ì—ì„œ êµ¬ì¡°í™”ëœ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ (Claude ì‚¬ìš© - ë¶„ì„ì )"""
        
        conversation_text = "\n".join([
            f"Q: {c['question']}\nA: {c['answer']}" 
            for c in conversation
        ])
        
        prompt = f"""ë‹¤ìŒ ì •êµí™”ëœ ì•„ì´ë””ì–´ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì •êµí™”ëœ ì•„ì´ë””ì–´:
{refined_idea}

ëŒ€í™” ë‚´ìš©:
{conversation_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
{{
    "main_topic": "í•µì‹¬ ì£¼ì œ (í•œ ë¬¸ì¥)",
    "target_audience": "íƒ€ê²Ÿ ë…ì (êµ¬ì²´ì ìœ¼ë¡œ)",
    "recommended_platform": {{
        "primary": "ë©”ì¸ í”Œë«í¼ (ë„¤ì´ë²„/í‹°ìŠ¤í† ë¦¬/ë¸ŒëŸ°ì¹˜ ë“±)",
        "reason": "ì„ ì • ì´ìœ ",
        "secondary": ["ë³´ì¡° í”Œë«í¼1", "ë³´ì¡° í”Œë«í¼2"]
    }},
    "evergreen_strategy": {{
        "rotation_topics": ["30ì¼ ë¡œí…Œì´ì…˜ ì†Œì£¼ì œ1", "ì†Œì£¼ì œ2", "ì†Œì£¼ì œ3"],
        "reusability": "ê¸€ê° ì¬í™œìš© ë°©ë²• (ì—°ë‹¨ìœ„ ë°˜ë³µ í™œìš© ì „ëµ)"
    }},
    "key_problems": ["í•´ê²°í•  ë¬¸ì œ 1", "í•´ê²°í•  ë¬¸ì œ 2"],
    "differentiators": ["ì°¨ë³„í™” í¬ì¸íŠ¸ 1", "ì°¨ë³„í™” í¬ì¸íŠ¸ 2"],
    "content_pillars": ["ì½˜í…ì¸  ê¸°ë‘¥ 1", "ì½˜í…ì¸  ê¸°ë‘¥ 2", "ì½˜í…ì¸  ê¸°ë‘¥ 3"],
    "content_style": "ì½˜í…ì¸  ìŠ¤íƒ€ì¼ (ì˜ˆ: ì‹¤ìš©ì  ê°€ì´ë“œ, ê²½í—˜ ê³µìœ  ë“±)",
    "monetization_strategy": {{
        "methods": ["ìˆ˜ìµí™” ë°©ë²•1", "ìˆ˜ìµí™” ë°©ë²•2"],
        "potential": "ìƒ/ì¤‘/í•˜",
        "reason": "ê·¼ê±°"
    }}
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì½”ë“œ ë¸”ë¡ ì—†ì´):"""

        # Claude ì‚¬ìš© (ì •êµí•œ ë¶„ì„ ë° ì¶”ì¶œ)
        response = self.hybrid_client.chat(
            prompt=prompt, 
            max_tokens=1000,
            task_type="analytical"  # Claude ì‚¬ìš©
        )
        
        # JSON íŒŒì‹±
        import json
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```" in response:
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
            
            details = json.loads(response.strip())
            return details
        except Exception as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "main_topic": refined_idea.split('\n')[0] if refined_idea else "",
                "target_audience": "",
                "recommended_platform": {
                    "primary": "ë„¤ì´ë²„ ë¸”ë¡œê·¸",
                    "reason": "ê¸°ë³¸ê°’",
                    "secondary": []
                },
                "evergreen_strategy": {
                    "rotation_topics": [],
                    "reusability": ""
                },
                "key_problems": [],
                "differentiators": [],
                "content_pillars": [],
                "content_style": "",
                "monetization_strategy": {
                    "methods": [],
                    "potential": "ì¤‘",
                    "reason": ""
                }
            }


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    refiner = IdeaRefinerNode()
    
    # ëŒ€í™”í˜• ëª¨ë“œ í…ŒìŠ¤íŠ¸
    initial = input("ğŸ’¡ ë¸”ë¡œê·¸ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not initial:
        initial = "ê°€ì¡± ì—¬í–‰ ë¸”ë¡œê·¸"
        print(f"(ê¸°ë³¸ê°’ ì‚¬ìš©: {initial})")
    
    # auto_mode=Falseë¡œ ì‹¤ì œ ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
    result = refiner.refine_interactive(initial, auto_mode=False)
    
    print("\n\n" + "="*80)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼")
    print("="*80)
    print(f"\nì´ˆê¸° ì•„ì´ë””ì–´: {result['initial_idea']}")
    print(f"\nì •êµí™”ëœ ì•„ì´ë””ì–´:\n{result['refined_idea']}")
    print(f"\nì¶”ì¶œëœ ì„¸ë¶€ ì •ë³´:")
    import json
    print(json.dumps(result['extracted_details'], ensure_ascii=False, indent=2))
