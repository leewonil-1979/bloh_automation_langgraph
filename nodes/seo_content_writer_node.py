"""
Step 4: SEO ì½˜í…ì¸  ìë™ ìƒì„± ë…¸ë“œ

30ì¼ ê³„íšì„ ë°›ì•„ ê° Dayë³„ë¡œ ì™„ì„±ëœ SEO ìµœì í™” ë¸”ë¡œê·¸ ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.

ì…ë ¥:
- 30ì¼ ì½˜í…ì¸  ê³„íš
- tone_style_guide.json (ë¬¸ì²´Â·í†¤ ê°€ì´ë“œ)
- SERP ì»¨í…ìŠ¤íŠ¸

ì¶œë ¥:
- content/dayXX_content.json (Day 1~30)
"""

import json
import logging
from typing import Dict, Any, List, Optional
from utils.llm_client import HybridLLMClient, LLMClient

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SEOContentWriterNode:
    """SEO ì½˜í…ì¸  ìë™ ìƒì„± ë…¸ë“œ"""
    
    def __init__(self):
        self.gpt = LLMClient()  # êµ¬ì¡° ìƒì„±ìš©
        self.claude = HybridLLMClient()  # ë³¸ë¬¸ ì‘ì„±ìš©
    
    def generate_all(
        self,
        content_plan: List[Dict[str, Any]],
        tone_guide: Dict[str, Any],
        serp_context: Optional[Dict[str, Any]] = None,
        start_day: int = 1,
        end_day: int = 30
    ) -> List[Dict[str, Any]]:
        """
        30ì¼ ê³„íšì„ ë°›ì•„ ì „ì²´ ì½˜í…ì¸  ìƒì„±
        
        Args:
            content_plan: 30ì¼ ì½˜í…ì¸  ê³„íš
            tone_guide: ë¬¸ì²´Â·í†¤ ê°€ì´ë“œ
            serp_context: SERP ë¶„ì„ ê²°ê³¼ (ì„ íƒ)
            start_day: ì‹œì‘ ì¼ì
            end_day: ì¢…ë£Œ ì¼ì
        
        Returns:
            ìƒì„±ëœ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ“ Step 4: SEO ì½˜í…ì¸  ìƒì„± ì‹œì‘ (Day {start_day}~{end_day})")
        
        results = []
        
        for day_num in range(start_day, end_day + 1):
            if day_num > len(content_plan):
                logger.warning(f"âš ï¸  Day {day_num}ëŠ” ê³„íšì— ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            day_plan = content_plan[day_num - 1]
            logger.info(f"\nğŸ“Œ Day {day_num}: {day_plan.get('title', 'N/A')}")
            
            # ë‹¨ì¼ ê¸€ ìƒì„±
            content = self.generate_single(day_num, day_plan, tone_guide, serp_context)
            results.append(content)
            
            logger.info(f"   âœ… Day {day_num} ì™„ë£Œ ({len(content.get('content', ''))}ì)")
        
        logger.info(f"\nğŸ‰ ì´ {len(results)}ê°œ ì½˜í…ì¸  ìƒì„± ì™„ë£Œ!")
        return results
    
    def generate_single(
        self,
        day_num: int,
        day_plan: Dict[str, Any],
        tone_guide: Dict[str, Any],
        serp_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ Day ì½˜í…ì¸  ìƒì„±
        
        Args:
            day_num: Day ë²ˆí˜¸
            day_plan: í•´ë‹¹ Day ê³„íš
            tone_guide: ë¬¸ì²´Â·í†¤ ê°€ì´ë“œ
            serp_context: SERP ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            ì™„ì„±ëœ ì½˜í…ì¸ 
        """
        # 1ë‹¨ê³„: GPTë¡œ êµ¬ì¡° ìƒì„± (H2/H3, í‘œ, ë¦¬ìŠ¤íŠ¸, FAQ)
        structure = self._generate_structure(day_num, day_plan, tone_guide, serp_context)
        
        # 2ë‹¨ê³„: Claudeë¡œ ë³¸ë¬¸ ì‘ì„± (ì˜¤í”„ë‹, ê° ì„¹ì…˜ ë³¸ë¬¸, CTA)
        full_content = self._write_content(day_num, day_plan, structure, tone_guide, serp_context)
        
        return full_content
    
    def _generate_structure(
        self,
        day_num: int,
        day_plan: Dict[str, Any],
        tone_guide: Dict[str, Any],
        serp_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸€ êµ¬ì¡° ìƒì„± (ë¹ ë¥´ê³  ì €ë ´)
        """
        title = day_plan.get("title", "ì œëª© ì—†ìŒ")
        category = day_plan.get("category", "ì¼ë°˜")
        keywords = day_plan.get("keywords", [])
        
        # SERP í‚¤ì›Œë“œ ì¶”ê°€
        if serp_context:
            serp_keywords = serp_context.get("top_keywords", [])
            keywords.extend(serp_keywords[:5])
        
        h2_count = tone_guide.get("seo_rules", {}).get("h2_count", 6)
        h3_per_h2 = tone_guide.get("seo_rules", {}).get("h3_per_h2", 2)
        
        prompt = f"""ë‹¹ì‹ ì€ SEO ìµœì í™” ë¸”ë¡œê·¸ ê¸€ êµ¬ì¡° ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ê²€ìƒ‰ ì—”ì§„ ìµœì í™”ëœ ê¸€ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

# ê¸€ ì •ë³´
- Day: {day_num}
- ì œëª©: {title}
- ì¹´í…Œê³ ë¦¬: {category}
- í‚¤ì›Œë“œ: {', '.join(keywords[:10])}

# êµ¬ì¡° ìƒì„± ê·œì¹™
- H2 ê°œìˆ˜: {h2_count}ê°œ
- H2ë‹¹ H3: {h3_per_h2}ê°œ
- í‘œ(Table) 1ê°œ: ë¹„êµ/ìš”ì•½ìš©
- ë¦¬ìŠ¤íŠ¸ 1ê°œ: ì²´í¬ë¦¬ìŠ¤íŠ¸/ë‹¨ê³„ë³„
- FAQ 3ê°œ: ì‹¤ì œ ê²€ìƒ‰ ì˜ë„ ê¸°ë°˜

# ì¶œë ¥ í˜•ì‹ (JSON)
{{
  "seo_title": "48~58ì, í‚¤ì›Œë“œ ì•ë°°ì¹˜, ìˆ«ì í¬í•¨",
  "meta_description": "110~150ì, í–‰ë™ ìœ ë„ í¬í•¨",
  "h1": "ë©”ì¸ ì œëª©",
  "sections": [
    {{
      "h2": "H2 ì œëª© (ì§ˆë¬¸í˜•/ìˆ«ìí˜•)",
      "h3_list": ["H3-1", "H3-2"],
      "content_outline": "ì´ ì„¹ì…˜ì—ì„œ ë‹¤ë£° ë‚´ìš© ê°œìš” 1~2ë¬¸ì¥"
    }}
  ],
  "table": {{
    "title": "í‘œ ì œëª©",
    "headers": ["ì—´1", "ì—´2", "ì—´3"],
    "rows": [
      ["ë°ì´í„°1-1", "ë°ì´í„°1-2", "ë°ì´í„°1-3"],
      ["ë°ì´í„°2-1", "ë°ì´í„°2-2", "ë°ì´í„°2-3"]
    ],
    "insert_after_section": 2
  }},
  "checklist": {{
    "title": "ì²´í¬ë¦¬ìŠ¤íŠ¸/ë¦¬ìŠ¤íŠ¸ ì œëª©",
    "items": ["í•­ëª©1", "í•­ëª©2", "í•­ëª©3", "í•­ëª©4", "í•­ëª©5"],
    "insert_after_section": 3
  }},
  "faq": [
    {{
      "question": "ì‹¤ì œ ê²€ìƒ‰ë  ë§Œí•œ ì§ˆë¬¸",
      "answer_outline": "ë‹µë³€ ê°œìš” 1ë¬¸ì¥"
    }},
    {{
      "question": "ì§ˆë¬¸2",
      "answer_outline": "ë‹µë³€ ê°œìš”"
    }},
    {{
      "question": "ì§ˆë¬¸3",
      "answer_outline": "ë‹µë³€ ê°œìš”"
    }}
  ],
  "internal_links": [
    {{
      "anchor_text": "ê´€ë ¨ ê¸€ ë§í¬ í…ìŠ¤íŠ¸",
      "target_day": 5,
      "insert_after_section": 1
    }}
  ],
  "image_prompts": [
    {{
      "position": "thumbnail",
      "prompt": "DSLR ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
      "alt_text": "SEO ìµœì í™” ALT í…ìŠ¤íŠ¸"
    }},
    {{
      "position": "section_2",
      "prompt": "ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸",
      "alt_text": "ALT í…ìŠ¤íŠ¸"
    }}
  ]
}}

ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        response = self.gpt.chat(prompt, max_tokens=2000)
        
        # JSON íŒŒì‹±
        try:
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            
            structure = json.loads(json_str)
            logger.info(f"   âœ… êµ¬ì¡° ìƒì„± ì™„ë£Œ (H2 {len(structure.get('sections', []))}ê°œ)")
            return structure
        except Exception as e:
            logger.error(f"âŒ êµ¬ì¡° JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._get_default_structure(title, h2_count)
    
    def _get_default_structure(self, title: str, h2_count: int = 6) -> Dict[str, Any]:
        """êµ¬ì¡° ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’"""
        return {
            "seo_title": title[:55],
            "meta_description": f"{title}ì— ëŒ€í•œ ì™„ë²½í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ì„¸ìš”!",
            "h1": title,
            "sections": [
                {
                    "h2": f"ì„¹ì…˜ {i+1}",
                    "h3_list": [f"ì†Œì£¼ì œ {i+1}-1", f"ì†Œì£¼ì œ {i+1}-2"],
                    "content_outline": "ë‚´ìš© ê°œìš”"
                }
                for i in range(h2_count)
            ],
            "table": {
                "title": "ë¹„êµí‘œ",
                "headers": ["í•­ëª©", "ë‚´ìš©"],
                "rows": [["ì˜ˆì‹œ1", "ì„¤ëª…1"], ["ì˜ˆì‹œ2", "ì„¤ëª…2"]],
                "insert_after_section": 2
            },
            "checklist": {
                "title": "ì²´í¬ë¦¬ìŠ¤íŠ¸",
                "items": ["í•­ëª©1", "í•­ëª©2", "í•­ëª©3"],
                "insert_after_section": 3
            },
            "faq": [
                {"question": "ì§ˆë¬¸1", "answer_outline": "ë‹µë³€"},
                {"question": "ì§ˆë¬¸2", "answer_outline": "ë‹µë³€"},
                {"question": "ì§ˆë¬¸3", "answer_outline": "ë‹µë³€"}
            ],
            "internal_links": [],
            "image_prompts": [
                {
                    "position": "thumbnail",
                    "prompt": "ë°ê³  ë”°ëœ»í•œ ê°€ì¡± ì´ë¯¸ì§€",
                    "alt_text": title
                }
            ]
        }
    
    def _write_content(
        self,
        day_num: int,
        day_plan: Dict[str, Any],
        structure: Dict[str, Any],
        tone_guide: Dict[str, Any],
        serp_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Claudeë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë³¸ë¬¸ ì‘ì„± (ê³ í’ˆì§ˆ)
        """
        title = day_plan.get("title", "")
        category = day_plan.get("category", "")
        
        # í†¤ ê°€ì´ë“œ ì¶”ì¶œ
        personality = tone_guide.get("tone_guide", {}).get("personality", "ì¹œê·¼í•˜ê³  ê³µê°í•˜ëŠ”")
        voice = tone_guide.get("tone_guide", {}).get("voice", "1ì¸ì¹­")
        opening_pattern = tone_guide.get("structure_template", {}).get("opening", {}).get("pattern", "")
        closing_pattern = tone_guide.get("structure_template", {}).get("closing", {}).get("pattern", "")
        paragraph_rule = tone_guide.get("writing_rules", {}).get("paragraph_spacing", "2~3ì¤„ë§ˆë‹¤ ê³µë°±")
        optimal_length = tone_guide.get("content_length", {}).get("optimal", 1800)
        
        # SERP ì¸ì‚¬ì´íŠ¸
        serp_insight = ""
        if serp_context:
            top_keywords = serp_context.get("top_keywords", [])[:5]
            if top_keywords:
                serp_insight = f"\n\n# SERP ì¸ê¸° í‚¤ì›Œë“œ\n{', '.join(top_keywords)}"
        
        prompt = f"""ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ SEO ìµœì í™” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ êµ¬ì¡°ì— ë§ì¶° ë…ìê°€ ëê¹Œì§€ ì½ê³  ì‹¶ì–´í•˜ëŠ” ê³ í’ˆì§ˆ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.

# ê¸€ ì •ë³´
- Day: {day_num}
- ì œëª©: {title}
- ì¹´í…Œê³ ë¦¬: {category}
- ëª©í‘œ ê¸€ì ìˆ˜: {optimal_length}ì{serp_insight}

# ë¬¸ì²´Â·í†¤ ê°€ì´ë“œ
- ì„±ê²©: {personality}
- ìŒì„±: {voice}
- ì˜¤í”„ë‹: {opening_pattern}
- ë§ˆë¬´ë¦¬: {closing_pattern}
- ë‹¨ë½ ê·œì¹™: {paragraph_rule}

# ê¸€ êµ¬ì¡° (ë°˜ë“œì‹œ ë”°ë¥¼ ê²ƒ)
{json.dumps(structure, ensure_ascii=False, indent=2)}

# ì‘ì„± ê·œì¹™
1. **ì˜¤í”„ë‹** (80~120ì)
   - ê°œì¸ ê²½í—˜ìœ¼ë¡œ ê³µê° ìœ ë„
   - ìì—°ìŠ¤ëŸ½ê²Œ ë¬¸ì œ ì œê¸°
   - ë…ìì˜ í˜¸ê¸°ì‹¬ ìê·¹

2. **ë³¸ë¬¸** (ê° ì„¹ì…˜)
   - H2ë§ˆë‹¤ ì´ëª¨ì§€ 1ê°œ ì‚¬ìš©
   - 80~140ì ë‹¨ë½, 3~4ë¬¸ì¥
   - í•µì‹¬ í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
   - êµ¬ì²´ì  ì˜ˆì‹œ/ìˆ˜ì¹˜ í¬í•¨
   - í‘œëŠ” insert_after_section ìœ„ì¹˜ì— ì‚½ì…
   - ë¦¬ìŠ¤íŠ¸ë„ ì§€ì • ìœ„ì¹˜ì— ì‚½ì…

3. **FAQ** (ë³¸ë¬¸ ë§ˆì§€ë§‰)
   - 3ê°œ ì§ˆë¬¸ê³¼ ê°„ê²°í•œ ë‹µë³€
   - ê²€ìƒ‰ ì˜ë„ ì¶©ì¡±

4. **ë§ˆë¬´ë¦¬** (60~100ì)
   - í•µì‹¬ ìš”ì•½ 1ë¬¸ì¥
   - í–‰ë™ ìœ ë„ (CTA)
   - ë‹¤ìŒ ê¸€ ì˜ˆê³  (ì„ íƒ)

5. **ë‚´ë¶€ ë§í¬**
   - ê´€ë ¨ Day ê¸€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
   - "ì´ì „ì— ì†Œê°œí•œ [ë§í¬] ê¸€ë„ ì°¸ê³ í•˜ì„¸ìš”"

# ì¶œë ¥ í˜•ì‹ (JSON)
{{
  "day": {day_num},
  "title": "{title}",
  "seo_title": "êµ¬ì¡°ì˜ seo_title ê·¸ëŒ€ë¡œ",
  "meta_description": "êµ¬ì¡°ì˜ meta_description ê·¸ëŒ€ë¡œ",
  "h1": "êµ¬ì¡°ì˜ h1 ê·¸ëŒ€ë¡œ",
  "opening": "ì˜¤í”„ë‹ ì „ì²´ í…ìŠ¤íŠ¸ (80~120ì)",
  "sections": [
    {{
      "h2": "êµ¬ì¡°ì˜ H2 ê·¸ëŒ€ë¡œ",
      "h2_emoji": "ğŸ“Œ",
      "h3_contents": [
        {{
          "h3": "êµ¬ì¡°ì˜ H3 ê·¸ëŒ€ë¡œ",
          "paragraphs": [
            "ë‹¨ë½1 í…ìŠ¤íŠ¸ (80~140ì)",
            "ë‹¨ë½2 í…ìŠ¤íŠ¸",
            "ë‹¨ë½3 í…ìŠ¤íŠ¸"
          ]
        }}
      ]
    }}
  ],
  "table_html": "êµ¬ì¡°ì˜ í‘œë¥¼ HTMLë¡œ ë³€í™˜ (<table>...</table>)",
  "checklist_html": "êµ¬ì¡°ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜ (<ul><li>...</li></ul>)",
  "faq": [
    {{
      "question": "êµ¬ì¡°ì˜ ì§ˆë¬¸",
      "answer": "ì™„ì„±ëœ ë‹µë³€ (2~3ë¬¸ì¥)"
    }}
  ],
  "closing": "ë§ˆë¬´ë¦¬ ì „ì²´ í…ìŠ¤íŠ¸ (60~100ì)",
  "internal_links": [
    {{
      "anchor_text": "ë§í¬ í…ìŠ¤íŠ¸",
      "target_day": 5,
      "context": "ë§í¬ ì£¼ë³€ ë¬¸ë§¥"
    }}
  ],
  "word_count": 1800,
  "keywords_used": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]
}}

ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
ë°˜ë“œì‹œ {optimal_length}ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        response = self.claude.chat(
            prompt=prompt,
            task_type="creative",
            max_tokens=4000
        )
        
        # JSON íŒŒì‹±
        try:
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            
            content = json.loads(json_str)
            
            # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•© (ê²€ì¦ìš©)
            full_text = content.get("opening", "")
            for section in content.get("sections", []):
                for h3_content in section.get("h3_contents", []):
                    full_text += " ".join(h3_content.get("paragraphs", []))
            full_text += content.get("closing", "")
            
            content["full_text"] = full_text
            content["full_text_length"] = len(full_text)
            
            logger.info(f"   âœ… ë³¸ë¬¸ ì‘ì„± ì™„ë£Œ ({len(full_text)}ì)")
            return content
        except Exception as e:
            logger.error(f"âŒ ë³¸ë¬¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"ì‘ë‹µ: {response[:300]}")
            return self._get_default_content(day_num, title, structure)
    
    def _get_default_content(
        self, 
        day_num: int, 
        title: str, 
        structure: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’"""
        return {
            "day": day_num,
            "title": title,
            "seo_title": structure.get("seo_title", title),
            "meta_description": structure.get("meta_description", ""),
            "h1": structure.get("h1", title),
            "opening": "ì´ ê¸€ì—ì„œëŠ” ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.",
            "sections": [
                {
                    "h2": section.get("h2", ""),
                    "h2_emoji": "ğŸ“Œ",
                    "h3_contents": [
                        {
                            "h3": h3,
                            "paragraphs": [
                                "ë‚´ìš©ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.",
                                "ìì„¸í•œ ë‚´ìš©ì€ ê³§ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤."
                            ]
                        }
                        for h3 in section.get("h3_list", [])
                    ]
                }
                for section in structure.get("sections", [])
            ],
            "table_html": "<table><tr><td>ë‚´ìš©</td></tr></table>",
            "checklist_html": "<ul><li>í•­ëª©1</li></ul>",
            "faq": structure.get("faq", []),
            "closing": "ë„ì›€ì´ ë˜ì…¨ê¸°ë¥¼ ë°”ëë‹ˆë‹¤!",
            "internal_links": [],
            "word_count": 500,
            "keywords_used": [],
            "full_text": "ê¸°ë³¸ í…ìŠ¤íŠ¸",
            "full_text_length": 500
        }


if __name__ == "__main__":
    import sys
    import os
    
    # ì…ë ¥ íŒŒì¼ ë¡œë“œ
    try:
        with open("outputs/initial_pipeline_result.json", "r", encoding="utf-8") as f:
            pipeline_result = json.load(f)
            content_plan = pipeline_result.get("content_plan", [])
            serp_result = pipeline_result.get("serp_result", {})
    except FileNotFoundError:
        logger.error("âŒ outputs/initial_pipeline_result.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    try:
        with open("outputs/tone_style_guide.json", "r", encoding="utf-8") as f:
            tone_guide = json.load(f)
    except FileNotFoundError:
        logger.error("âŒ outputs/tone_style_guide.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        logger.error("   ë¨¼ì € python -m nodes.tone_style_generator_nodeë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # ìƒì„± ì˜µì…˜
    print("\n" + "="*80)
    print("ğŸ“ SEO ì½˜í…ì¸  ìë™ ìƒì„±")
    print("="*80)
    print(f"\nì´ {len(content_plan)}ì¼ ê³„íšì´ ìˆìŠµë‹ˆë‹¤.")
    print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("  1. ì „ì²´ ìƒì„± (Day 1~30)")
    print("  2. ë²”ìœ„ ì§€ì • (ì˜ˆ: Day 1~5)")
    print("  3. ë‹¨ì¼ Day (ì˜ˆ: Day 1)")
    
    choice = input("\nì„ íƒ (1/2/3, ê¸°ë³¸ê°’=3): ").strip() or "3"
    
    start_day = 1
    end_day = 1
    
    if choice == "1":
        start_day = 1
        end_day = len(content_plan)
    elif choice == "2":
        start_input = input("ì‹œì‘ Day (ê¸°ë³¸ê°’=1): ").strip() or "1"
        end_input = input(f"ì¢…ë£Œ Day (ê¸°ë³¸ê°’={min(5, len(content_plan))}): ").strip() or str(min(5, len(content_plan)))
        start_day = int(start_input)
        end_day = int(end_input)
    else:  # choice == "3"
        day_input = input("ìƒì„±í•  Day (ê¸°ë³¸ê°’=1): ").strip() or "1"
        start_day = end_day = int(day_input)
    
    # ë¹„ìš©/ì‹œê°„ ì˜ˆì¸¡
    count = end_day - start_day + 1
    estimated_cost = count * 35  # â‚©35/ê¸€
    estimated_time = count * 30  # 30ì´ˆ/ê¸€
    
    print(f"\nğŸ“Š ì˜ˆìƒ ì •ë³´:")
    print(f"   - ìƒì„± ê°œìˆ˜: {count}ê°œ")
    print(f"   - ì˜ˆìƒ ë¹„ìš©: â‚©{estimated_cost}")
    print(f"   - ì˜ˆìƒ ì‹œê°„: {estimated_time}ì´ˆ ({estimated_time//60}ë¶„ {estimated_time%60}ì´ˆ)")
    
    confirm = input(f"\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’=y): ").strip().lower() or "y"
    if confirm != "y":
        print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    
    # ìƒì„± ì‹¤í–‰
    writer = SEOContentWriterNode()
    results = writer.generate_all(
        content_plan=content_plan,
        tone_guide=tone_guide,
        serp_context=serp_result,
        start_day=start_day,
        end_day=end_day
    )
    
    # ì €ì¥
    output_dir = "outputs/content"
    os.makedirs(output_dir, exist_ok=True)
    
    for content in results:
        day_num = content.get("day", 0)
        output_path = os.path.join(output_dir, f"day{day_num:02d}_content.json")
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(content, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ Day {day_num} ì €ì¥: {output_path}")
    
    # ìš”ì•½ ì €ì¥
    summary = {
        "generated_at": "2025-11-14",
        "total_count": len(results),
        "start_day": start_day,
        "end_day": end_day,
        "total_cost_krw": estimated_cost,
        "files": [f"day{c.get('day', 0):02d}_content.json" for c in results]
    }
    
    summary_path = os.path.join(output_dir, "generation_summary.json")
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*80)
    print("âœ… SEO ì½˜í…ì¸  ìƒì„± ì™„ë£Œ!")
    print("="*80)
    print(f"\nğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
    print(f"ğŸ“Š ì´ {len(results)}ê°œ íŒŒì¼ ìƒì„±")
    print(f"\në‹¤ìŒ ë‹¨ê³„: python -m nodes.image_planner_node")
